from datetime import datetime, timedelta
now = datetime.now().date()
start = datetime(2016,6,21).date()
from bs4 import BeautifulSoup
import requests
import csv

with open("/Users/MAD/Desktop/Thesis/Python/Floor Sheet/"+str(now)+".csv", "w") as f:
    wr = csv.writer(f)    
    wr.writerow(["S.N","Traded Company","Transaction ID","Buyer Broker","Seller Broker","Share Qty","Rate","Amount"])
    x = 1
    while x <= 15:    
        r = requests.get("http://nepalstock.com.np/main/floorsheet/index/"+str(x)+"/id/desc/YTo1OntzOjExOiJjb250cmFjdC1ubyI7czowOiIiO3M6MTI6InN0b2NrLXN5bWJvbCI7czowOiIiO3M6NToiYnV5ZXIiO3M6MDoiIjtzOjY6InNlbGxlciI7czowOiIiO3M6NjoiX2xpbWl0IjtzOjM6IjUwMCI7fQ?contract-no=&stock-symbol=&buyer=&seller=&_limit=500")
        soup = BeautifulSoup(r.content,'lxml')

        table = soup.select_one("table.my-table")
        cols_tr = table.select_one("tr.unique")
        # write all row data.
        wr.writerows([td.text.strip() for td in row.find_all("td")]
                    for row in cols_tr.find_all_next("tr")
                        if row.find("td").text.isdigit())
        x += 1


import mysql.connector

config = {
  'user': 'scott',
  'password': 'password',
  'host': '127.0.0.1',
  'database': 'employees',
  'raise_on_warnings': True,
  'use_pure': False,
}

cnx = mysql.connector.connect(**config)

cnx.close()
